<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[2018年终总结]]></title>
    <url>%2F2018%2F12%2F30%2F2018%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[时光荏苒，日月如梭，不知不觉我们已经走到了 2018 年的尽头。 工作 2018 年是我职业生涯的第二年，却是在三易的新开始。年初的时候，公司的一切对我来说都是那么陌生，我的目标就是能尽快的跟大家伙混个脸熟。然而事与愿违，由于工位不足，我只能被安排在其他项目组的办公室里面进行工作，虽说平时跟附近的同僚们也会聊上几句，但由于工作内容并无交集，所以并没擦出有多少火花。 幸运的是后来重新编排了座位，沟通终于方便了，再加上大家加了几次班，友谊的小船慢慢在变大。沟通方便了，那很多事情做起来都顺畅了很多，例如对产品需求的疑问，对代码的的疑问，都能够很快的得到解答。似乎所有事情看起来都那么井井有条，公司的业务也在不断发展，项目组的人数也在噌噌的往上涨。 在 2018 年的工作中，我们最主要的任务就是完成新需求的开发以及修复 BUG ，而让我印象深刻的任务或者紧急事件主要有以下这些： 抽奖活动事故 微信推文定时推送 特殊的 UV 统计 之所以印象深刻必然是因为它们有特殊之处。就例如事故1发生的那天，负责该项目的同事因为连夜赶工调了休，然后由我来负责追踪问题。获取项目权限，理清项目结构，再了解完大概流程才真正开始寻找问题，花费了很多不必要是时间。这让我意识到了即使项目再小，也要提前分配后勤人员，才能以防万一。 而任务2、3的特殊性在于我考虑这些任务的解决方案的时候，能够跳出自己旧的知识体系，去了解更多的方法和数据结构，以及如何灵活的解决问题。我清楚的知道即使我用已掌握的知识也能够实现这些功能，但是我更知道能够实现和优雅的实现并不是一回事，它们所考虑的东西不止差一丁半点。 无论是任务还是事故，明面上是考验解决问题的能力，但是暗地里校验着人的决策能力。解决问题的方案有很多种，有的人会去找轮子，而有的人会改轮子，还有的人会写轮子，没有孰优孰劣的说法，只有合适与否。合适与否又要考虑到很多因素，时效、成本、拓展、性能、安全等，所以你最终选择的方案代表了你所有的思考。 计划 回首 2018 ，我在年初给自己定下了几个计划： 努力学习，认真工作，学以致用（1/1） 保持日常记录笔记和温习的习惯（1/1） 希望输入之余也能够对外输出知识（1/1） 复习高等数学、线性代数等基础知识（1/2） 重新啃一遍操作系统，争取看懂50%并实践（0/1） 假如学有余力，希望可以摸一下AI技术的大门（0/1） 前些年买了很多书没看，争取今年读透2本技术相关书籍（0.5/2） 计划看上去十分的饱满而充实，但是有句古话说得好：计划赶不上变化，所以上面一些的比较细粒度的计划并没有执行得很好😂。如大家所见每条计划后面的比例就是完成度，实际上因为觉得第4点和第6点在短期内对个人的提升来说不会有太大作用，所以中途决定暂停了这两项计划。但是我认为也并没有浪费了4、5、6、7点计划的时间在毫无用处的地方上面，而是将它们用在了其他的一些的计划上面： 保持每天一定的运动量（207/273） 除了身体的运动脑子也要运动，数学题或算法题都能帮到我（1/1） 加入学习英语打卡队伍，扩充词汇量，希望日后能够比较流畅的交流（120/121） 这部分的计划几乎都是年中才决定的，决定重拾运动的计划是因为易胖和食神体质的我自从去年停止了运动之后已经重了二十多斤了，最重要的是再胖下去会影响到身体健康。而第二点是因为在看技术文章的时候，发现有时候会卡在解决思路和数据结构里面不能理解，所以我认为最好的方法就是多看多练多动脑。而第三点则是老同学想找人一起承担一些课程套餐的 quota ，因为一个人很难在限定时间内用完所有的 quota ，我考虑了一下就加入到队伍里面去了。 目标 上面主要陈述的是今年的一些计划，但凡说到计划，就不能没有目标，没有计划的目标是空想，没有目标的计划是瞎做。虽说最终的目标肯定是自身的成长和价值的体现，但是实际上一年时间说多还真不多，想要说实现了这么泛而宏大的目标是不切实际的，所以我在这里归纳总结，希望能描绘出通往最终目标路上的已完成的一些小目标： 乐观、积极向上的生活状态，享受生活，爱我所爱 学习不停留在应用层面，希望能深入弄懂内在的原理和实现方式 造一些轮子，尽管可能不够别人的好，但你的轮子也能有自己的特色 在肥胖的道路上停下了脚步，希望能重新踏上健康的大道 英语词汇量有一定的提升，沟通交流上有较为明显的进步 以上五点皆为我认为在 2018 年达到了的一些小目标，大部分是学习相关的目标，而只有第一点是关于生活的。说实话关于 2018 生活方面的总结好像是挤不出别的东西了，因为相比去年更多的时间都是宅在家里，跟同学朋友联络也不算少，但绝大多数都是在开黑语音上面😂。 未来 以上就是我对于 2018 年的总结，有进步，也有不足。而对于 2019 ，我有以下几点展望： 持续学习，不要给自己设定边界，学无止境 加强外交，不能仅仅在网络交流，要来就来真的 阅览群书，不止于技术相关书籍，更多的了解技术之外的世界 关于 2018 年，丧的事情有千千万，我都不在文中提及。 Life is like a roller coaster，总是起起落落落落落落。但，塞翁失马焉知非福。我们只管风雨兼程，时间会给出最后的答案。 完。]]></content>
      <categories>
        <category>总结</category>
      </categories>
      <tags>
        <tag>summary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis之神奇的HyperLogLog]]></title>
    <url>%2F2018%2F11%2F18%2FRedis%E4%B9%8B%E7%A5%9E%E5%A5%87%E7%9A%84HyperLogLog%2F</url>
    <content type="text"><![CDATA[这篇笔记想码很久了，于是今天码完上一篇二维码的文章后立马先占个坑，免得后面又被其他题材冲掉了。 在某一天开完了需求会议之后，我新的工作任务中包含了一项统计浏览量的任务。关于这项任务的详细需求大致如下： 每个用户（user_id）每天浏览过该数据(1~n次)算一个单位浏览量 能够统计每条数据一直以来总的浏览量 能够得出15天内的按浏览量排序总排行榜和地区排行榜 能够得出15天内的实际的UV总排行榜和地区排行榜 允许存在数分钟的数据更新延迟 允许出现小程度误差 由于怕概念有点混淆，所以我这篇文章里将以一天为单位的UV称为浏览量，将以15天为单位的UV称为UV 相信大家看到上面列出的要点后也进行了一轮思考，不知道大家是否理解了浏览量和UV的概念。或许大家能够想到很多种方案，不管是轻捷的、复杂的、常规的还是骚气的，都希望大家可以分享一下，而我在此也分享一下自己的思路以及实现过程。 从标题中就可以看到，本文将使用到Redis，以及Redis新支持的一种数据类型HyperLogLog。实际上一开始我并不清楚HyperLogLog的使用方法，但是从需求出发，有序集合SortedSet是需要的，而剩下的步骤，就看自己对Redis的理解能不能骚出点东西来了。 由于Redis的特性，我认为它能够成为一个很好的中转站，但不应该是一个仓库，所以总的浏览量我最终会选择存储到Mysql等关系型数据库中，而Redis缓存下来的，则是15天内的数据。假设我们的SortedSet中存储的是汇总了15天内的浏览量数据，那么第一个问题，就是我们如何计算得出总浏览量。如我们定时将缓存数据存入Mysql，而Mysql中我们只用一个字段存储这个总浏览量，那么那么我们在第16天的时候，总浏览量就会丢失掉第一天的数据。所以我在这里使用了三个字段来协助总浏览量的存储，一个是当天浏览量，第二个是今天前的总浏览量，剩下一个是缓存更新时间，为了方便，下面我们会将： 总浏览量称为total_view 当天浏览量称为day_view 今天前的总浏览量称为total_view_bt 缓存更新时间称为cache_update_time 所以最终我们的total_view = day_view + total_view_bt，当定时更新数据库数据的时候，如果当前时间跟cache_update_time是同一天，则只更新day_view值，如果不是同一天，则会先将total_view_bt更新为total_view_bt + day_view，然后再将day_view替换为Redis中的当天浏览量数据。 这样我们Mysql的总浏览量存储是搞定了，那么接下来我们就需要用Redis存储好这15天的浏览量了，那这每天的数据我们应该用什么结构去存储呢？我们先来回顾一下需求，首先我们的需求只需要统计浏览量，而不需要知道这个数据具体被哪些用户浏览过，那么就是说明我们不需要知道我存储的实际内容，而另一方面，我们需要的是最近15天的数据，而15天前的数据已被存储到Mysql中，所以第1天的数据应该在第16天凌晨就过期了。 终上所诉，在大家都熟悉的Redis五种数据类型中，能满足需求的，我个人认为只有SortedSet是比较符合的（注意这里的SortedSet跟上面汇总的SortedSet不是同一个）。如果使用SortedSet，我想到两种方案，一种是以data_id + user_id + day作为SortedSet里面元素的键，以过期时间作为score通过定时任务剔除过期数据；另外一种是使用data_id + day作为键，即一个数据存储15个SortedSet，然后再单独设置过期时间。但是上述两种方案都存在一些比较麻烦的问题，例如： 方案一需要代码维护SortedSet；方案二需要复杂的去重统计UV 方案一和方案二都需要一次性获取全部数据进行统计浏览量以及排序 SortedSet的插入需要O(N)的时间复杂度，影响效率 我们完全不需要知道我存储的实际内容，使用SortedSet比较浪费空间 认真的思考过后发现存在较多的问题，那到底还有没有其他比较好的方案可以使用呢？或许我们可以开阔一下视野，不要局限于我们常用的数据类型上。后来我是想起了之前比较热门的一篇文章：如何判断一个数是否在40亿个整数中？，这篇文章讲到了bitmap的使用，而bitmap也是Redis最新支持的数据类型之一，于是我就去阅读关于Redis新支持的两种数据类型的文章了。看完之后豁然开朗，发现bitmap和HyperLogLog都比较满足我们对效率、空间和简单编码的要求，最后就采用了HyperLogLog的数据类型去实现我们的需求。 先简单的介绍一下HyperLogLog的特性和操作，首先HyperLogLog是用来做基数统计的，基数统计指的是指统计一个集合中不同的元素的个数，下面摘录一段源于《HyperLogLog the analysis of a near-optimal cardinality estimation algorithm》的简述： 在理想状态下，将一堆数据hash至[0,1]，每两点距离相等，1/间距 即可得出这堆数据的基数。然而实际情况往往不能如愿，只能通过一些修正不断的逼近这个实际的基数。实际采用的方式一是分桶，二是取kmax。分桶将数据分为m组，每组取第k个位置的值，所有组中得到最大的kmax，(k-1)/kmax得到估计的基数。 HyperLogLog算法的另一个主观上的理解可以用抛硬币的方式来理解。以当硬币抛出反面为一次过程，当你抛n次硬币全为正面的概率为1/2n。当你经历过k(k很大时)次这样的过程，硬币不出现反面的概率基本为0。假设反面为1，正面为0，每抛一次记录1或者0，当记录上显示为0000000…001时，这种可以归结为小概率事件，基本不会发生。转换到基数的想法就是，可以通过第一个1出现前0的个数n来统计基数，基数大致为2(n+1)时。硬币当中可以统计为(1/21+1/42+1/8*3…)，大致可以这么去想。 有兴趣深入了解的童鞋可以Google一下上面的论文，下面我们回归到如何在Redis中操作HyperLogLog上来。Redis中一共有三种操作HyperLogLog的方法： PFADD: 将任意数量的元素添加到指定的HyperLogLog里面。作为这个命令的副作用，HyperLogLog内部可能会被更新， 以便反映一个不同的唯一元素估计数量（也即是集合的基数）。如果HyperLogLog估计的近似基数在命令执行之后出现了变化， 那么命令返回1， 否则返回0。 如果命令执行时给定的键不存在， 那么程序将先创建一个空的HyperLogLog结构， 然后再执行命令。 PFCOUNT：当PFCOUNT命令作用于单个键时， 返回储存在给定键的HyperLogLog的近似基数，如果键不存在，那么返回0。当PFCOUNT命令作用于多个键时，返回所有给定HyperLogLog的并集的近似基数，这个近似基数是通过将所有给定HyperLogLog合并至一个临时HyperLogLog来计算得出的。通过HyperLogLog数据结构，用户可以使用少量固定大小的内存，来储存集合中的唯一元素（每个HyperLogLog只需使用12k字节内存，以及几个字节的内存来储存键本身）。命令返回的可见集合（observed set）基数并不是精确值，而是一个带有0.81%标准错误（standard error）的近似值。 PFMERGE：将多个HyperLogLog合并（merge）为一个HyperLogLog，合并后的HyperLogLog的基数接近于所有输入HyperLogLog的可见集合（observed set）的并集。合并得出的HyperLogLog会被储存在destkey键里面，如果该键并不存在，那么命令在执行之前，会先为该键创建一个空的HyperLogLog。 知道了如何操作HyperLogLog后我们就开始用它来实现我们的需求吧。 首先我使用data_id + day作为SortedSet的键记录该资源数据当天的UV，其中day是由当前时间戳除以一天的秒数然后再模15得出的一个0~14的数，即day = (1543127511 // 86400) % 15，然后用户浏览的时候将用户的user_id存进去以及设置好过期时间，最后将data_id_day1到data_id_day15的数据循环用PFCOUNT取出来后相加的总和是每天的UV总和（即理解为15天内的浏览量），简称之为15UDV，而将data_id_day1到data_id_day15的数据一次性使用PFCOUNT得出来的结果是15天的UV结果，简称UV。那么15UDV和UV是两种不同排序依据，所以我们这里将此资源数据的UV值存入到最后用于排序的SortedSet里面。由于有总排行榜和城市排行榜，所以我们需要定义两种SortedSet： rank：15天UV总排行榜 rank_[city]：city替换为对应资源所在城市的15天UV城市排行榜 至于15UDV嘛，其实跟上面UV也是一样的操作，就不多说了。所以到这里所有步骤已经完成了，下面就展示一下的伪代码方便大家再理顺一下： # 存储过程 data_id = 1 city = 'guangzhou' user_id = 'ove1d291d2912ed1ad91e2' day = (now.timestamp // 86400) % 15 15day_after = now.date.timestamp + 15*86400 key = str(data_id) + '_' + str(day) this.redis.multi() this.redis.pfadd(key, user_id) this.redis.expireat(key, 15day_after) this.redis.exec() # 获取UV for i in range(15): keys = [str(data_id) + '_' + str(i)] UV = this.redis.pfcount(keys) # 获取15UDV 15UDV = 0 for i in range(15): udv_key = str(data_id) + '_' + str(i) 15UDV += this.redis.pfcount(udv_key) # 存储到排行榜中 rank_key = 'rank' city_rank_key = rank_key + '_' + city udv_rank_key = 'udv_rank' udv_city_rank_key = udv_rank_key + '_' + city this.redis.multi() this.redis.zadd(rank_key, UV, data_id) this.redis.zadd(city_rank_key, UV, data_id) this.redis.zadd(udv_rank_key, 15UDV, data_id) this.redis.zadd(udv_city_rank_key, 15UDV, data_id) this.redis.exec() # Mysql统计总浏览量 resource = orm.table('resource').get(data_id) if date(resource.cache_update_time) != date(now.timestamp): resource.total_view_bt += resource.day_view resource.day_view = this.redis.pfcount(key) resource.cache_update_time = now.timestamp resource.total_view = resource.total_view_bt + resource.day_view resource.save() 完。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二维码生成原理及编码实现]]></title>
    <url>%2F2018%2F10%2F16%2F%E4%BA%8C%E7%BB%B4%E7%A0%81%E7%94%9F%E6%88%90%E5%8E%9F%E7%90%86%E5%8F%8A%E7%BC%96%E7%A0%81%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[一年前挖的坑，现在来补，希望不会太晚。先把压舱底的笔记放上来以表我会填完坑的决心。当前还在整理和重写旧代码阶段，下面先把一些基础知识罗列出来。 11月9日更：最近工作比较忙，而且二维码的规则真的很烦杂多，虽然看上去总体代码量不多，结构也很随性，但是也花了半个月时间才完成了初版的功能。按之前说的，下面我会把一些基础知识列出来，但不会太过详尽，到编码实战章节将会详细解说。在仓库中有一份专门讲解二维码的构成以及解析规则的PDF全英说明书，如果大家觉得有哪点不太清楚的可以去PDF里面找-----&gt;代码仓库地址 简要笔记 40个标准版本、4个微型版本 四种编码方式： 数字：0-9 大写字母和数字：0-9，A－Z，空格，$%*±./: 二进制/字节：ISO/IEC 8859-1 日本汉字/假名：shift JISJIS X 0208 四种容错级别 L：7%字码可被修正 M：15%字码可被修正 Q：25%字码可被修正 H：30%字码可被修正 结构 版本信息 格式信息 数据及容错密钥 数据需求模块 定位标识 校正标识 定时标识 静态区域 功能性图样： 闷声区 定位标识 分隔符 定时标识 校正标识 编码区域： 格式信息 版本信息 数据及容错字码 编码QRCode流程： 数据分析 编码数据 计算容错码 组织数据 填充 应用数据掩码 填充格式信息和版本信息 基础图解 二维码的英文是QR Code(Quick Response Code)，它本质上是一种密码算法，近几年来成为了移动设备上非常流行的一种编码方式，它比传统的条形码能存更多的信息，也能表示更多的数据类型。二维码有 40 种尺寸，我们称其为Version。Version 1是21×21的矩阵，Version 2是25×25的矩阵，可以看到，每增加一个 Version，尺寸都会增加 4，所以尺寸Size与Version的关系为：Size = (Version - 1)*4 + 21。而Version的最大值是 40，故尺寸最大值是(40-1)*4+21 = 177，即 177 x 177 的矩阵。 结构示意图 二维码的组成基本上可被分为定位、功能数据、数据内容三部分。 定位图案 定位标识：用于标记二维码矩形的大小；用三个定位图案即可标识并确定一个二维码矩形的位置和方向了； 分隔符：用白边框将定位图案与其他区域区分； 定时标识：用于定位，二维码如果尺寸过大，扫描时容易畸变，时序图案的作用就是防止扫描时畸变的产生； 校正标识：只有在 Version 2 及其以上才会需要； 功能数据： 格式信息：存在于所有尺寸中，存放格式化数据； 版本信息：用于 Version 7 以上，需要预留两块 3×6 的区域存放部分版本信息； 数据内容： 数据 容错字码 纠错码、掩码、纠错级别信息记录标识 数据编码 接下来介绍二维码的编码方式。 Numeric mode 数字编码 从0到9。如果需要编码的数字的个数不是3的倍数，那么，最后剩下的1或2位数会被转成4或7bits，则其它的每3位数字会被编成 10，12，14bits，编成多长还要看二维码的尺寸 Alphanumeric mode 字符编码 包括 0-9，大写的A到Z（没有小写），以及符号$ % * + – . / : 包括空格。这些字符会映射成一个字符索引表。如下所示：（其中的SP是空格，Char是字符，Value是其索引值） 编码的过程是把字符两两分组，然后转成下表的45进制，然后转成11bits的二进制，如果最后有一个落单的，那就转成6bits的二进制。而编码模式和字符的个数需要根据不同的Version尺寸编成9, 11或13个二进制 Byte mode 字节编码 可以是0-255的ISO-8859-1字符。有些二维码的扫描器可以自动检测是否是UTF-8的编码。 Kanji mode 日文编码 也是双字节编码。同样，也可以用于中文编码。日文和汉字的编码会减去一个值。如：在0X8140 to 0X9FFC中的字符会减去8140，在0XE040到0XEBBF中的字符要减去0XC140，然后把结果前两个16进制位拿出来乘以0XC0，然后再加上后两个16进制位，最后转成13bit的编码。 其他编码 Extended Channel Interpretation (ECI) mode 特殊字符集 主要用于特殊的字符集，并不是所有的扫描器都支持这种编码 Structured Append mode 混合编码 说明该二维码中包含了多种编码格式 FNC1 mode 特殊行业编码 主要是给一些特殊的工业或行业用的，如GS1条形码等 掩码、纠错码等 在数据编码完成后，为了防止出现大面积的空白或黑块而导致识别困难，我们还需要做多一步操作。一共有8种掩码你可以使用，下图中包含八种掩码的图示以及公式。所谓掩码，就是和上面生成的图做异或操作，而且掩码只会作用于数据区域。最最后，我们得到的八种掩码与数据其余异或出来的数据矩阵实际上都可以作为二维码被识别，但是考虑到要让扫码器更加容易的识别，需要从八个数据矩阵中筛选出机器最容易辨别的，筛选的依据又涉及到一套惩罚计算的规则了。 掩码类型 二维码的纠错码主要是通过Reed-Solomon error correction来实现的。对于这个算法，可以说是相当的复杂，在短时间内也许我们不能完全理解他的算法含义，但是可以先了解它的一些基础知识以及步骤，如果觉得必须要完完全全搞清楚，建议查看相关的论文。由于本篇文章篇幅有限，在未完全理解该算法的情况下我不可能妄自总结，所以这里先推荐一篇稍微简单的介绍文章给各位感兴趣的读者：为程序员写的Reed-Solomon码解释 编码实战 骨架 好了本节进入了编码实战阶段，我们首先需要做的是先将整个二维码生成流程理清楚，并构造好对应的函数。 #!/usr/bin/python class Qrcode: mode = None level = None qrcode = None version = 1 data_matrix = None mask_id = None length = 0 size = () def generate(self, path): return def resize(self, size): return def paint(self, img, fg_or_bg=0): return def _matrix_to_img(self, img_mode='1', matrix=None): return def __init__(self, message, level_index='L'): return def decide_version(_message, _level_index): return def build_matrix(encode_data): def build_locate_sign(): return def build_time_sign(): return def build_dark_sign(): return def build_alignment_sign(): return def level_and_mask_build(_mask_id): return def build_version_info(): return def data_build(_encode_data): return def mask(): def mask_template(col, row, _mask_id): return def penalty(__matrix): return return def encode(_message): def get_data_codewords(__message): return def rs_encode(_data_codewords): return 我的代码抽丝剥茧后剩下的骨架大概就是以上的代码，和一开始我所打造的结构有一点区别，主要还是流程没有完全梳理好所导致的。所以大家常说理解好业务流程是项目环节中很重要的一环，它影响到整个项目的可扩展性以及日后的可维护性。在我个人看来优秀的程序员并不是指代码写得多么好、结构多么清晰、使用的技术多么高大上的人，而是能够真正的理解用户的真实诉求并加以分析以及能够梳理和完善流程的人。这种人无论在哪个行业，做什么样的工作，称之为优秀都是当之无愧的。 版本选择 二维码的版本最直接影响的就是二维码内容容量的多少，当然除了版本外影响容量的还有纠错等级，所以我们最先需要计算的是根据用户的传入信息量和选择的纠错级别得出应该使用哪个版本的二维码。 def __init__(self, message, level_index='L'): self.level = level_map[level_index] message = message.encode() def decide_version(_message, _level_index): if all(chr(i) in num_list for i in _message): mode = 'numeric' else: mode = 'byte' for each_version in range(40): if character_amount[_level_index][each_version][mode_map[mode]] &gt; len(_message): self.version = each_version + 1 if each_version + 1 &gt; self.version else self.version break self.length = 21 + 4 * (self.version - 1) self.size = (self.length, self.length) self.mode = mode decide_version(message, level_index) 为了容易理解，我把上下文的代码也贴到上面了。我使用的是python3，首先我们要先把信息内容encode()转化为一个个的byte，如果你不这样做python3拿出来的数据会是多个byte的组合，因为它已经能够识别多国语言了。接下来就是用每个版本对应纠错等级下的数据容量和当前需要编码的数据量进行对比了，一直到能容纳的数据量比需求的多，就可以停止对比更高的版本了。另外在这里我还进行了编码方式的指定，关于编码方式的说明可以接着看下一章节。 数据编码 数据编码这一节可以说是整个流程中最重要的、最核心的，二维码的数据识别以及纠错能力都是通过这一部分来实现的。大家可能比较奇怪为什么这么重要的一环代码量却并不多，实际上我们项目中并没有实现Reed-Solomon算法，而是使用了依赖库，所以该部分的代码仅仅只是进行数据切割组装以及使用依赖库中封装好的函数。当然，我也愿意为有兴趣查看依赖库源码的童鞋奉上地址：reedsolomon def encode(_message): def get_data_codewords(__message): def numeric_encode(___message): diff_encode_code = '' divided_arr = [___message[i:i + 3] for i in range(0, len(___message), 3)] for _equal_or_less_than_three_digits in divided_arr: respectively_len = 10 - 3 * (3 - len(_equal_or_less_than_three_digits)) diff_encode_code += bin(int(_equal_or_less_than_three_digits))[2:].zfill(respectively_len) return diff_encode_code def byte_encode(___message): diff_encode_code = '' for b in ___message: diff_encode_code += bin(b)[2:].zfill(8) return diff_encode_code mode_encode = { 'numeric': numeric_encode, 'byte': byte_encode, } incomplete_codewords = mode_indicator_map[self.mode] + bin(len(__message))[2:].zfill( character_count_indicator_map[self.version][mode_map[self.mode]]) + mode_encode[self.mode](_message) distance_to_8_multiple = 8 - (len(incomplete_codewords) % 8) incomplete_codewords += '0' * distance_to_8_multiple codewords = incomplete_codewords bytes_need = 8 * each_version_required_bytes[self.version][self.level] while len(codewords) &lt; bytes_need: codewords += '1110110000010001' if bytes_need - len(codewords) &gt;= 16 else '11101100' _data_codewords = [int(codewords[i:i + 8], 2) for i in range(len(codewords)) if not i % 8] return _data_codewords def rs_encode(_data_codewords): _encode_data, data_block, i = '', [], 0 block_codecount = num_of_error_correction_blocks_2_error_correction_per_blocks[self.version][self.level] for group1 in range(block_codecount[0]): data_block.append(_data_codewords[i:i + block_codecount[1]]) i += block_codecount[1] for group2 in range(block_codecount[2]): data_block.append(_data_codewords[i:i + block_codecount[3]]) i += block_codecount[3] nsym = ecc_num_version_level_map[self.version][self.level] gen = rs_generator_poly(nsym) ecc_num = len(gen) - 1 _ecc_data = [] for block in data_block: _data_block_get_ecc_block = block + [0] * ecc_num for i in range(len(block)): coef = _data_block_get_ecc_block[i] if coef != 0: for j in range(ecc_num + 1): _data_block_get_ecc_block[i + j] ^= gf_mul(gen[j], coef) _ecc_data.append(_data_block_get_ecc_block[len(block):]) _all_block_data = ''.join(bin(dec)[2:].zfill(8) for block in zip(*data_block) for dec in block) # 突出部分补全 for block in data_block: if len(block) == block_codecount[3]: _all_block_data += bin(block[block_codecount[3] - 1])[2:].zfill(8) _all_ecc_data = ''.join(bin(dec)[2:].zfill(8) for block in zip(*_ecc_data) for dec in block) return _all_block_data + _all_ecc_data + '0' * remainder_bits[self.version] data_codewords = get_data_codewords(_message) return rs_encode(data_codewords) 这一部分代码大家可以看到最主要由get_data_codewords和rs_encode组成，而get_data_codewords中又包含了numeric_encode和byte_encode这两种编码方式。我想大家应该记得，它们就是数据编码章节中介绍的其中两种编码方式。之所以没有编写其他的编码方式，主要原因有三： 不一样的编码方式实际上只是根据不同的编码所制定的规则不一样而已，万能的规则肯定是最受欢迎的 当今市面上大多数主流的扫码器支持自动检查byte_encode的数据是否是UTF-8的编码，换言之就是基本支持所有的语言的识别 其他的一些编码虽说在某种程度上能够节省一定的空间，可能能够降低二维码使用的版本使得扫码器更容易识别，但是本身过多的信息不应该通过二维码进行传播，而且如今的影像技术在识别高版本二维码上不会有太大的压力 终上所诉，在我的代码中只保留了两种编码方式，一种是对纯数字的编码方式，另外一种则是现在可以对所有编码都适用的编码方式。 说完了关于代码中的编码方式，接下来我们继续解说这段get_data_codewords的代码还干了什么。大家可以看到被编码的数据是最后才加上的，而编码数据前面有： mode_indicator_map[self.mode] + bin(len(__message))[2:].zfill(character_count_indicator_map[self.version][mode_map[self.mode]]) 其中的mode_indicator_map是你选择的编码模式的标识，如果是numeric模式需要加上0001， alphanumeric模式为0010， byte模式为0100， kanji模式为1000。而后面那段看起来很复杂的一串东西，实际上是数据长度的标识，先将输入的文本长度转化为二进制，然后查出不同版本下不同编码模式所需要的（文本长度）标识长度，接着用0去对该二进制数进行补齐缺省长度。最后加上数据编码后，如果整体数据的长度不是8的整数倍，还需要在数据后面用0进行补齐。 也许你已经被上面绕来绕去弄得晕头转向了，但这仅仅只是开始:)。接着，我们的得到的二进制数据长度还不够，我们要查到当前二维码版本以及纠错级别下的二维码需要数据区域的长度为多少，如果还没有达到需要的最大长度，我们还要轮流加两个补齐码11101100和00010001，没错轮流的意思就是11101100000100011110110000010001……。这就是完整的编码区数据编码了，我们称之为Data Codewords，每一个8bits叫一个codeword，我们还要对这些数据码加上纠错信息，所以我们对数据进行每8bits拆分并转化为了十进制，得到了一个充满十进制数的数组。 接下来就是rs_encode()函数的工作了，num_of_error_correction_blocks_2_error_correction_per_blocks这里我有一个常量命名非常的长，它代表着每个版本和纠错等级下所需纠错码的block数量，映射关系的格式为(1, 19, 0, 0)或(2, 38, 2, 39)，如果第三个数为0，说明所有的block所需要的codeword数量是一样的，反则反之，最多可能会有两组block。第二和第四个参数则代表每个block所需要的codeword数量。分组分block后就是到了计算纠错码的步骤了，如果想要理解这部分的详细步骤和原理可以参考 掩码、纠错码等 中我提供的链接。 现在我们手上既有Data Codewords，也得到了对应的纠错码，最后一步就是将他们组合成我们二维码数据区域中所需要的完整的数据了。至于怎么合起来呢，还是需要点骚操作的。上面我们得到的多组多block的Data Codewords和纠错码都是二维数组，那么也就是矩阵啦，接下来我们需要做的是将矩阵转置，然后将里面元素转化为二进制并用0补齐到8位后一行一行的串连起来，Data Codewords和纠错码两个矩阵都需要进行此操作。在这里的处理中我一开始忘了分组后的codeword是不一样的，矩阵转置后会丢掉某一组多出的元素，所以我们需要补上这一部分的数据。 到这里数据编码部分是真正的结束了，是不是有点复杂？没事多看几次就能够熟悉了:) 填充数据矩阵 现在我们离二维码出生只有两步之遥了，接下来都是很简单的东西了:) 基础图解 中可以看到，版本信息、格式信息、定位标志、校正标志、定时标志这些都是不依赖数据内容的（当然，它们受数据长度影响），接下来我们就构造一个二维码的矩阵，先把这些相对固定的数据填充进去。 def build_locate_sign(): for i in range(8): for j in range(8): if i in (0, 6): self.data_matrix[i][j] = self.data_matrix[-i - 1][j] = self.data_matrix[i][ -j - 1] = 0 if j == 7 else 1 elif i in (1, 5): self.data_matrix[i][j] = self.data_matrix[-i - 1][j] = self.data_matrix[i][ -j - 1] = 1 if j in (0, 6) else 0 elif i == 7: self.data_matrix[i][j] = self.data_matrix[-i - 1][j] = self.data_matrix[i][-j - 1] = 0 else: self.data_matrix[i][j] = self.data_matrix[-i - 1][j] = self.data_matrix[i][ -j - 1] = 0 if j in (1, 5, 7) else 1 def build_time_sign(): for i in range(self.length): self.data_matrix[i][6] = self.data_matrix[6][i] = 1 if i % 2 == 0 else 0 def build_dark_sign(): for j in range(8): self.data_matrix[8][j] = self.data_matrix[8][-j - 1] = self.data_matrix[j][8] = \ self.data_matrix[-j - 1][8] = 0 self.data_matrix[8][8] = 0 self.data_matrix[8][6] = self.data_matrix[6][8] = self.data_matrix[8][-8] = 1 if self.version &gt; 6: for i in range(6): for j in (-9, -10, -11): self.data_matrix[i][j] = self.data_matrix[j][i] = 0 def build_alignment_sign(): point_matrix = [] if alignment_location[self.version]: for i in alignment_location[self.version]: for j in alignment_location[self.version]: point_matrix.append((j, i)) matrix_len = len(point_matrix) for index in range(len(point_matrix)): if index == 0 or index == sqrt(matrix_len) - 1 or index == matrix_len - (sqrt(matrix_len) - 1) - 1: continue else: for x_offset in range(-2, 3): for y_offset in range(-2, 3): self.data_matrix[point_matrix[index][0] + x_offset][point_matrix[index][1] + y_offset] \ = 1 if x_offset % 2 == 0 and y_offset % 2 == 0 or abs(x_offset) + abs( y_offset) == 3 else 0 def level_and_mask_build(_mask_id): for format_i in range(len(format_info_str[self.level][_mask_id])): self.data_matrix[format_i if format_i &lt; 6 else ( format_i + 1 if format_i &lt; 8 else self.length - 7 + (format_i - 8))][8] = int( format_info_str[self.level][_mask_id][format_i]) self.data_matrix[8][format_i if format_i &lt; 6 else ( format_i + 1 if format_i &lt; 8 else self.length - 7 + (format_i - 8))] = int( format_info_str[self.level][_mask_id][14 - format_i]) self.data_matrix[self.length - 8][8] = int(format_info_str[self.level][_mask_id][7]) def build_version_info(): if self.version &gt; 6: _version_info = version_info_str[self.version][::-1] for num_i in range(len(_version_info)): self.data_matrix[num_i // 3][num_i % 3 + self.length - 11] = int(_version_info[num_i]) self.data_matrix[num_i % 3 + self.length - 11][num_i // 3] = int(_version_info[num_i]) 上面的代码分别就是定位标志、定时标志、黑点、校正标志、格式信息、版本信息的填充代码了。咦不对，怎么多了个黑点这个奇怪的东西？哈哈，这个东西其实是固定在这里的： 神奇的黑点 定位标志、黑点、定时标志 定位标志大小是不会变的，只有位置会根据版本变化；黑点我想就不用多说了，就是那里的一点；而定时标志就是黑白相间连接在定位标志之间。 定位标识图示 校正标志 从Version 2才开始有校正标志的出现，它们应该出现的坐标记录在常量alignment_location中，例如Version 2中的(6, 18)，代表x轴和y轴分别在6和18上面相交的四个点：(6,6),(6,18),(18,6),(18,18)，其他版本的也是以此类推，下图是Version 8的图示，如果交点上已经被定位标志所占，则该点就不会有校正标志。 而校正标志的尺寸大小就如下图所示： 格式信息 接着就到格式信息出场了，格式信息一共有两条，避免其中一条被遮挡而导致读取不到信息： 格式信息的长度为15bits，每一个bit的位置如下图所示： 这15个bits中，前2个bits用于表示纠错级别，接着3个bits表示掩码，最后10个bits用于纠错的，也是通过reedsolo来计算得出。最后15个bits还要与101010000010010做异或操作。这样就保证不会因为我们选用了00的纠错级别和000的掩码而造成整个格式信息为白色。综上所述，格式信息总共只有(纠错级别*掩码样式)4*8=32种可能，所以我们这里只要把他们最后的结果都列出来，我们就不用做什么计算了，根据纠错级别和掩码选就可以了:) 版本信息 版本信息是从Version 7开始才需要添加的，它会出现在以下两个位置： 版本信息的长度为18bits，其中6bits为版本号，剩下的12bits为纠错码。因为这个也是固定的，所以我们还是老样子，将所有版本的版本信息数据放到了version_info_str里面，按需获取即可。而填充的顺序如下图所示： 编码数据填充 最后就是填充我们的得到的数据区域编码了，填充方式如下图：从右下角开始沿着红线填写我们的各个bits。如果遇到了上面的非数据区域，则跳过。 这一步相对来说比较简单，代码如下： def data_build(_encode_data): up = True bit = (int(i) for i in _encode_data) for _block_end_x in range(self.length - 1, 0, -2): _block_end_x = _block_end_x if _block_end_x &gt; 6 else _block_end_x - 1 for y in range(self.length - 1, -1, -1) if up else range(self.length): for x in (_block_end_x, _block_end_x - 1): if self.data_matrix[x][y] is None: self.data_matrix[x][y] = next(bit, 0) up = not up 应用掩码并选择最佳的二维码 记得之前说过还剩两步，但我掐指一算发现我的心算出现了错误，但这次真的是到了最后两步了:) 如果童鞋们忘记了掩码是干嘛用的，可以回到 掩码、纠错码等 回顾一下。那么一共有八种掩码，他们的代号和表达式的映射关系如下： 那我们首先要做的就是把表达式写好了。 def mask_template(col, row, _mask_id): if _mask_id == 0: return (col + row) % 2 == 0 elif _mask_id == 1: return row % 2 == 0 elif _mask_id == 2: return col % 3 == 0 elif _mask_id == 3: return (row + col) % 3 == 0 elif _mask_id == 4: return (row // 2 + col // 3) % 2 == 0 elif _mask_id == 5: return ((row * col) % 2) + ((row * col) % 3) == 0 elif _mask_id == 6: return (((row * col) % 2) + ((row * col) % 3)) % 2 == 0 elif _mask_id == 7: return (((row + col) % 2) + ((row * col) % 3)) % 2 == 0 else: return (col + row) % 2 == 0 那么下一步我们就是将二维码矩阵代入到八种掩码运算中了： penalty_result = [] _matrix_with_mask = [] for mask_id in range(8): level_and_mask_build(mask_id) _matrix = [[None] * self.length for _i in range(self.length)] for x in range(self.length): for y in range(self.length): if self.data_matrix[x][y] is not None: _matrix[x][y] = self.data_matrix[x][y] ^ mask_template(x, y, mask_id) penalty_result.append(penalty(_matrix)) _matrix_with_mask.append(_matrix) 计算得到了八个结果后，我们还需要从里面筛选出最佳的二维码，计算的规则是一套惩罚计算，惩罚值越低，说明二维码越容易被扫码器识别。惩罚计算的规则有四种，四种惩罚只相加得到最终的惩罚值。N1是计算行或列连续相同色块大于5的区域，N2是计算大面积色块的区域，N3是寻找连续四空色块0000连接1011101色块，N4是计算二维码中的黑白平衡。惩罚力度如下图所示： def penalty(__matrix): def cal_n3(___matrix): _count = 0 check_word = ('00001011101', '10111010000') for row in ___matrix: row_str = ''.join(str(s) for s in row) begin = 0 while begin &lt; len(row_str) and check_word[0] in row_str[begin:]: begin += row_str[begin:].index(check_word[0]) + len(check_word[0]) _count += 1 begin = 0 while begin &lt; len(row_str) and check_word[1] in row_str[begin:]: begin += row_str[begin:].index(check_word[1]) + len(check_word[1]) _count += 1 return _count def get_sum(___matrix): num = 0 for v in ___matrix: if v is list: num += get_sum(v) return num + sum(map(sum, ___matrix)) n1 = 0 n2 = 0 n3 = 0 n4 = 0 # N1寻找连续同色块which &gt;= 5 for reverse in range(0, 2): for j in range(reverse, self.length): count = 1 adj = False for i in range(1 - reverse, self.length): if __matrix[j][i] == __matrix[j][i - 1]: count += 1 else: count = 1 adj = False if count &gt;= 5: if not adj: adj = True n1 += 3 else: n1 += 1 # N2寻找m * n的同色块 count = 0 for j in range(self.length): for i in range(self.length): if __matrix[j][i] == __matrix[j - 1][i] and __matrix[j][i] == \ __matrix[j][i - 1] and __matrix[j][i] == __matrix[j - 1][i - 1]: count += 1 n2 += 3 * count # N3寻找连续四空色块0000连接1011101色块 # 一个方向寻找 + 另一个方向(矩阵转置) transposition_matrix = list(zip(*__matrix)) n3 += 40 * cal_n3(__matrix) + cal_n3(transposition_matrix) # N4计算黑色块占比 dark = get_sum(__matrix) percent = dark // pow(self.length, 2) * 100 pre = percent - percent % 5 nex = percent + 5 - percent % 5 n4 = min(abs(pre - 50) / 5, abs(nex - 50) / 5) * 10 return n1 + n2 + n3 + n4 计算得出所有的二维码的惩罚值后，我们选择那个惩罚值最小的作为最终的二维码矩阵。 _best_mask_id = penalty_result.index(min(penalty_result)) self.data_matrix = _matrix_with_mask[_best_mask_id] return _best_mask_id 生成图片 至此二维码矩阵已经生成并选取完毕了，下面的工作就只是按照矩阵生成图片了，由于我还有其他骚操作，下面的代码并不是简单的直接生成图片，不过也包含在里面了，大家可以拉代码下来慢慢看。 def generate(self, path): if self.qrcode is None: self._matrix_to_img() if self.gif_combine: self.gif_qrcode[0].save(path, save_all=True, append_images=self.gif_qrcode, duration=self.duration, loop=0) else: self.qrcode.save(path) return def _matrix_to_img(self, img_mode='1', matrix=None): border = abs(int(self.border)) size = (self.length + 2 * border, self.length + 2 * border) img = Image.new(img_mode, size, img_mode_2_color_map[img_mode][0]) for x in range(self.length): for y in range(self.length): img.putpixel((x + border, y + border), (img_mode_2_color_map[img_mode][0] - self.data_matrix[x][y]) if matrix is None else matrix[x][y]) self.qrcode = img 结束 二维码的原理以及代码实战到这里就完结了，一年前机缘巧合看到了一篇二维码的介绍文章，一时兴起就跟着写了一个Version 1和H纠错级别的二维码生成代码，但是局限性太大了，而且不支持中文编码，就一直想着写成比较通用的库，但是迟迟没有下手。这次终于拿出了半个月时间重温了一遍并且实现了较为通用的版本，另外还添加了一些定制性的东西进去。当然我的解说以及代码不具备权威性，如果有兴趣验证和深入了解的童鞋，可以参考以下的资料和代码： https://github.com/sylnsfar/qrcode https://coolshell.cn/articles/10590.html https://zhuanlan.zhihu.com/p/21463650 https://www.thonky.com/qr-code-tutorial/ https://www.jianshu.com/p/8208aad537bb https://github.com/tomhaoye/qrcode/blob/master/pdf/SC031-N-1915-18004Text.pdf 完。]]></content>
      <categories>
        <category>有趣</category>
      </categories>
      <tags>
        <tag>other</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[极验滑动验证码行为模拟]]></title>
    <url>%2F2018%2F09%2F01%2F%E6%9E%81%E9%AA%8C%E6%BB%91%E5%8A%A8%E9%AA%8C%E8%AF%81%E7%A0%81%E8%A1%8C%E4%B8%BA%E6%A8%A1%E6%8B%9F%2F</url>
    <content type="text"><![CDATA[为了能看到具体的效果，使用了selenium+chrome进行实验，如果大家想要打包下载即用，可以自行修改搭配PhantomJS食用。 经过一番折腾成功率已经比较高了（70%-90%吧【2018/10/01】），某些背景干扰元素过多缺口又刚好在色差较小的地方的时候可能会计算错误，也可能还有某些特殊的情况，GIF是旧的，具体可看MP4。 代码仅供参考学习交流，有兴趣可以拿去玩玩，鉴于本人能力有限，代码、逻辑以及解决方式上有错误在所难免，请各位大佬多多指教~ 另外我发现极验官网快改版了，鉴于该代码直接在极验官网上模拟，可能很快就用不了了，届时可以考虑接入api到自己本地再进行模拟测试。 仓库地址: https://github.com/tomhaoye/geetest-crack-demo 故事起源 之前写了个爬虫抓取58的小区数据的代码，有人提了个issue，说小区详情数据和经纬度为空，我自己试了一把，发现请求太频繁会被强制跳转到验证码的页面去。 后来试用了代理，发现一个ip没抓几条数据就被强制跳转人机校验了，然后我手动去访问网页并通过验证码的校验之后再去抓取数据，发现抓取了几千条数据也没有再被强跳了。 这是什么规则=。=算了，还是先想办法能自动通过人机校验先。而58的这个页面的人机校验，是类似于极验的那种滑动验证码。emmmm，网上资料都很多，但是版本较旧，现在的极验滑动校验改进了不少地方，不过思路总是可以参考了。 步骤分解 屏幕出现滑动行为验证码框 截取验证码合成图片\获取验证码原图片 图片处理以及缺口定位 将拼图移动到缺口处 后续：关于干扰块排除的想法 后续：关于增加定位模拟难度的想法 开始研究 0、屏幕出现滑动行为验证码框 我首先找到使用极验控件的地方，例如：极验官网，然后点击到滑动行为验证框出现。这个行为使用selenium模拟比较简单，关于如何使用selenium进行元素定位、模拟点击等这里就不多介绍了，有需要学习的找谷歌百度皆可，有前端基础的一小时内就能够上手。 1、截取验证码合成图片\获取验证码原图片 1.1、获取验证码原图片 现在滑动行为验证框已经出现了，接下来应该是想办法拿到原图片，或者是直接截取当前合成好的图片，两种做法有本质上什么区别呢？首先先说一下获得原图片，极验在加载校验控件的时候会请求三张图片，其中一张是缺口原图，另外一张是完整原图，还有一张是拼块。 缺口原图 完整原图 大家可以看到，请求的所获取到的原图，都是打散重组过的图片，我读过一些解析的文章，有的提到重新组合到一起的方法写在代码里面，而有的文章则是表示散块映射关系是有接口请求的，这也许是大家研究的版本不一样所导致的。我下载了一些原图的组合进行了观察，倒是发现了每一组原图的其实打散前后的散块的位置应该是固定的，也就是说映射关系应该是固定的。其实我觉得，无论映射关系是在前端代码里，还是在接口里，只要你需要在客户端进行重组的，那就相当于没有秘密，所以多一事不如少一事，直接使用固定的映射关系倒是省事不少。 1.2、截取验证码合成图片 这一小节是关于获取图片的，图片处理会在下一小节，所以接下来说一下直接截取合成的图片。所谓所见即所得，能够获取到人眼直接看到的图像，才是最接近人类行为的模拟，而如果通过其他方式取巧，哪天他的方式改了，你的逻辑就不适用了。就像我后来观察58的滑动行为验证，它家请求的图片就是完整的合成图，所以遵循正常人类行为才是究极奥义啊。至于如何截取动行为验证框中的合成图片，我们需要定位到验证框所属的位置，于是乎我先定位到一个class为geetest_window的div，拿到它当前的位置以及长宽属性，接着截图整个当前页面的，并根据刚刚获得的位置以及长宽属性对当前页面图片进行裁剪，就可以获得我们人眼所看到的合成图片了。 def cut_gt_window_image(browser): image_div = browser.find_element_by_class_name(&quot;geetest_window&quot;) location = image_div.location size = image_div.size top, bottom, left, right = location['y'], location['y'] + size['height'], location['x'], location['x'] + size[ 'width'] screen_shot = browser.get_screenshot_as_png() screen_shot = image.open(BytesIO(screen_shot)) captcha = screen_shot.crop((left, top, right, bottom)) captcha.save(cut_image_path) return browser 合成图片 通过这一小节我们对于获取图片的方式和方法已经了然于胸，现在就让我们进入下一小节，对刚刚所获得的图片进行分析和研究吧。 2、图片处理以及缺口定位 2.1、处理打散的原图片与定位缺口位置 在上一小节，我们已经猜测过是打散过的图片跟实际上正常的图片的映射关系是固定的，所以我先尝试对其中一张缺口原图的打散图片进行重组。重组的关键其实就是找到散块跟原来位置的映射关系就行了，于是我拿着打散图片跟合成好的图片一块一块的对比，发现了它实际上是将正常的图片分为上下两部分，然后上下两部分再分为26份进行打散的。关于位置的映射关系，由于时间关系，我就动用了我的火眼金睛直接得到了结果： {1: 18, 2: 17, 3: 15, 4: 16, 5: 22, 6: 21, 7: 14, 8: 13, 9: 10, 10: 9, 11: 19, 12: 20, 13: 2, 14: 1, 15: 6, 16: 5, 17: 26, 18: 25, 19: 23, 20: 24, 21: 7, 22: 8, 23: 3, 24: 4, 25: 11, 26: 12} 这里的映射关系是图片上半部分的，而下半部分的映射关系，我找了前两个散块的原本对应位置，就大概能猜到其实就是使用上半部分的映射关系相邻两值交换后的结果，例如上半部分是1:18, 2:17那么到了下半部分就是1:17, 2:18，下面就是具体的还原图片代码： def merge_img(img_path='', target=''): im = image.open(img_path) to_image = image.new('RGB', (260, 160)) dx = 12 dy = 80 x = 0 img_map = {1: 18, 2: 17, 3: 15, 4: 16, 5: 22, 6: 21, 7: 14, 8: 13, 9: 10, 10: 9, 11: 19, 12: 20, 13: 2, 14: 1, 15: 6, 16: 5, 17: 26, 18: 25, 19: 23, 20: 24, 21: 7, 22: 8, 23: 3, 24: 4, 25: 11, 26: 12} while x &lt;= 300: y = 0 while y &lt;= 80: from_img = im.crop((x, y, x + dx, y + dy)) second_line = img_map[(x / 12) if ((x / 12) % 2) else (x / 12 + 2)] - 1 loc = ((img_map[x / 12 + 1] - 1) * 10 if y else second_line * 10, abs(y - dy)) to_image.paste(from_img, loc) y += dy x += dx to_image = to_image.convert('L') to_image.save(target) return to_image 补充一点，大家看到的打散图片的宽度是312个像素的，而我这里最后还原的得到的图片宽度却是260像素，这是因为打散图片的每一个相邻散块之间实际上是有重叠部分的，一开始我合成得到的宽度312像素的图片时候发现图片是变了样的，所以最后将他们重叠部分堆叠在一起，才得到了正常的原始图片。 还原完整图片 还原缺口图片 缺口图和完整图都可以如法炮制，最后为了方便对比，进行了灰度化处理。接下来由于自身对各种图片格式并不熟悉，碰了不少壁，我会另外再写一篇关于图片格式的学习笔记，完工后会把链接贴过来，有需要的童鞋可以自取，这里我就不详细说自己怎么坑自己的了。 那我们来进入正题，两张完整的图片已经到手了，接下来就应该是定位缺口的起始位置了。童鞋们可以用肉眼看到，两张图片除了缺口位置，其他部分基本是完全一样的，所以思路很简单，就是对两张图片逐个像素点进行对比，然后第一个有差别的位置，是不是就是缺口的起始位置呢？ 换作先前的版本或许是对的，但现在来说大概是错的，为什么这么说呢？比较多前辈的文章中提到第一个差异的位置就是缺口的起点，但是那是基于打散图片后使用的压缩标准是无损压缩，如果使用了有损压缩（或者说支持有损压缩的标准），那么得到的缺口图片和完整图片就不一定只有缺口部分有差异了。不过好在我们知道，即使是有损压缩，也只是损失部分细节，肉眼上看到的差异并不明显，对于计算机来说，就是颜色变化并不大，对于灰度图片来说，我们可以认为是灰度值相差较小。而我们缺口位置，因为需要通过人眼能够清晰的辨别，所以它跟周围的灰度值相差应该是比较大的。于是我们就能够想到去找到这个灰度值相差的阈值，去进行区分到底是缺口还是因为有损压缩所带来的细节损失。分析大概就是到这了，下面是具体的代码： def enlarge_diff_image(bg_path='', fbg_path='', save_path=''): bg_img = image.open(bg_path) fbg_img = image.open(fbg_path) img = image.new('L', (260, 160)) for i in range(260): for j in range(160): if abs(bg_img.getpixel((i, j)) - fbg_img.getpixel((i, j))) &gt; 40: img.putpixel((i, j), bg_img.getpixel((i, j))) else: img.putpixel((i, j), 255) img.save(save_path) 差异瞄点图 上面的图片就是自己坑自己的代表作，因为我将打散图还原后使用了有损压缩，最后对比的结果出来了很多干扰点，虽然通过一定的规则去定位缺口的实际位置没有太大问题，但是大家还是尽量使用无损压缩的图片进行对比会比较妥当。当然你们可以不将还原后的图片保存就直接进行对比，我这里为了方便步骤分解，躺了一次坑，学到新姿势，倒不是坏事。 无损差异瞄点图 得到这样的图片，大家想要求缺口起始位置与左边框的像素就十分简单了，当然我们还可以继续处理，将图片真正的二值化，不过最后求移动距离都是只要求第一个0点（黑点）的像素点就行，以防万一还可以加上对范围内0点（黑点）面积阈值判断。 二值化图 缺口图和完整图的缺口定位并不太难，大概到这里就可以结束了，然我们进入下一小小节。 2.2、处理截取的合成图片与定位缺口位置 这部分的图片的处理和分析对我来说应该是这个小demo里面最难的点了，我知道现在的人工智能领域已经比较强大了，对很多图片内容的认知甚至超过了人类，解决这个问题或许很简单。而我则是没有深入学习过这些方面的知识，但依然想凭借自己现有的技能和思想去解决这个问题。因为前面也说过，这种方式的分析才是最接近人类行为的，只要人类认知图片内容的方式不发生变化，这里面的逻辑就还能用，于是就风风火火的开干吧。 说干就干也不能立刻就写代码，毕竟我们还不知道要怎么对一张图片进行处理和分析，才能够找到那个我们需要的结果。还是先想几条路子出来吧： 缺口和周围有明显的颜色区别，我们能不能以此来确定接口位置？ 滑块和缺口都是比较规矩的拼图形状，而且y轴的范围是一样的，我们能不能在水平方向上找到两条或多条相似的竖线？ 基于上面的想法，我也是尝试做了两套方案出来。 方案一：反正就是想办法把缺口涂黑 好饿好困啊，明天继续写。 好了今天搬完砖回家继续码字。这一方案的最初的想法就是直接根据缺口的颜色范围来确认缺口到底在图中哪个地方，但是后面实现起来却发现是有不少问题的，到最后这个方案所得出来的位置虽有些时候确实能成功，但是准确率比较低。具体问题如下： 大家看到缺口处的颜色大概是由背景加上一层有透明度的灰色渐变图层所组成的，而组合出来的颜色很大程度取决于背景颜色，所以颜色范围就太大了，很容易把背景其他内容也选出来。 有那么两张图背景是偏暗的，如果说缺口没有明显边界的话，那么缺口其实通过肉眼也比较难观察出来，那么这种情况下我们最终描绘出来的图片可能是一大片都是缺口区域，因为缺口和背景融为一体了。 下面是这个方案的代码，没有太多次的去修改，因为颜色范围确实是不可控的，后来干脆也灰度化再对一定灰度范围描绘了。 def get_bin_image(img_path='', save_path='', t_h=150, t_l=60): img = image.open(img_path) img = img.convert('L') table = [] for i in range(256): if i in range(t_l, t_h): table.append(0) else: table.append(1) binary = img.point(table, '1') binary.save(save_path) 二值化结果图 emmmm，得到这个图片，其实是比较理想的情况，缺口周围没有太多的干扰元素，定位缺口的还是比较容易的。大家认真数过可以知道，缺口和拼图的宽度（不算凹凸部分）是42个像素，而拼图与边框的左边距是6像素（拼图突出部分不在左边的情况下），那么缺口的x轴范围就应该是从第49个像素开始。那么我们在这范围内进行缺口起点的查找，可以沿用之前的想法，就是第一个满足一定规律(连续的黑点数量或者比例、范围内黑点面积占比等等)的黑点，我们可以认为他比较大概率是缺口的起点。具体的代码： def get_x_point(bin_img_path=''): tmp_x_cur = 0 img = image.open(bin_img_path).load() # 缺口出现范围大概在x轴[49-52]-220,y轴15-145 for y_cur in range(15, 145): b_acc = 0 tmp_x_cur = 0 for x_cur in range(49, 220): if img[x_cur, y_cur] == 0: if b_acc == 0: tmp_x_cur = x_cur b_acc += 1 else: if b_acc in range(36, 44): return tmp_x_cur - 40 + b_acc else: b_acc = 0 return tmp_x_cur 这个函数我后来没有继续去优化了，因为觉得想到了方案二的一些雏形，就开始着手方案二了。这个函数定义的规则相当的简陋，即使排除了上面提到的问题，有的时候都还是不能准确判断起始位置。大家有兴趣的话可以自己定制一些规则，尝试提升这种方案的成功率。 方案二：对图片所有内容进行描边 关于这个方案，其实一开始并没有觉得比第一个方案好到哪里去，最后试验得出的结果却较为满意，我认为应该还是归功于较为完善的规则。无论是哪个方案，只要是模仿人类认知行为的，都有一定的可行性，尽管方式上有区别，但是这就跟人类认知事物的过程是一样的。例如我们在认识鸡这种动物的时候，既记住了它们的棕黄色的毛，红色的冠，也记住了它们的外形，那我们在下次看到一只乌鸡的时候，我们能够通过它的外形确认这是一只鸡，只是一只颜色不一样的鸡而已，没人会因为它的毛是黑色的而觉得它是一只黑猫。通过捕捉人类区分事物特征点的方式去思考以及编码，才是解决这次实验的关键。 好了，又到了新的一天，今天我继续说说方案二的实验过程。在这节一开始我就简单的描述过方案二，不过可能表述得并不清晰，这里再简洁的说一下，其实第一步，就是先对图像内有明显边界的东西进行描边。例子如下： 截取的原图 描边图 这里我们得到的图片跟原图里面的事物轮廓基本相符的，相信大家都能发现他们的相似之处，而不同之处大概表现在了内容的颜色上面。得到的黑白图片对于我们很有帮助，因为在这里它所表达的信息对于我们来说比五彩斑斓的原图直观得多。下面是代码，具体的方法其实就是通过边界与相邻像素点的颜色差异比较大而得出来的。 def get_contour_image(img_path='', save_path=''): contour_img = image.new('1', (260, 160)) img = image.open(img_path) img = img.convert('L') h_last_point = None v_last_point = None for x in range(260): for y in range(160): if v_last_point is not None and abs(img.getpixel((x, y)) - v_last_point) &gt; 25: contour_img.putpixel((x, y), 1) v_last_point = img.getpixel((x, y)) for y in range(160): for x in range(260): if h_last_point is not None and abs(img.getpixel((x, y)) - h_last_point) &gt; 25: contour_img.putpixel((x, y), 1) h_last_point = img.getpixel((x, y)) contour_img.save(save_path) 既然边界已经描绘出来了，接下来我们就是想办法去定位缺口了。方案二所得到的图片内容比较丰富，基本与原图是没有差别的，那我们就不能够通过方案一中最初规则去定位缺口了，因为在里面满足规则的色块很多很多，所以我们应该为方案二量身定做一套新规则。 现在我们需要做的是观察描边图并找到并找到隐藏在其中的一些信息，大家可以看到：缺口附近的描边十分规整，而拼块附近的描边比较粗大；缺口描边内的黑块面积应该跟拼块描边内的黑块面积差不多；缺口跟拼块在y轴上的范围基本是一样的。接下来我们就利用刚刚观察到的这些信息进行分析，看看能不能得出一定的规律，制定出适当的规则。 从上面的信息中，有的可能自身就能够成为规则，而有的则需要进行组合，也许大家能够找到更多的信息，也能制定很多的规则。而我想到的规则，也许存在不完善或者错误的的地方，但我也想在这里跟大家分享，希望大家指点指点。之前我们寻找缺口基本都是整幅图去遍历所有像素点的，这样很容易被其他的元素所干扰。所以我就想能不能先确定一个方向上（例如y轴）的范围，然后就只需要在（例如x轴上）找到满足的点或线，记录起来最后再做筛选。这里我选取了拼块的左白边作为定位y轴范围的依据，因为他开始于x轴上的第7个像素（原图），而x轴上的7之前的像素基本是没有其他元素干扰的，这让定位y轴范围变得比较方便和准确。一般来说，我们只需要找到x轴上第七个像素（索引为6）在y轴上每连续42个像素（拼块长宽度）中哪个范围白点（描边）最多，那么这个范围就是拼块和缺口左描边的范围。当然，事实上还有特殊的情况，先上个代码再来慢慢解释。 def get_start_point(bin_img_path=''): img = image.open(bin_img_path) # 滑块左边位置7px[6\13]处，获取滑块位置 _pixel = 42 _color_diff_list = {} initial_slider_left_x_index_range = range(6, 14) for initial_slider_left_x_index in initial_slider_left_x_index_range: back_color_n = 0 slider_left = {} for y_cur in range(118): color_n = 0 for add_to_next in range(_pixel): color_n += img.getpixel((initial_slider_left_x_index, y_cur + add_to_next)) slider_left[color_n] = y_cur w_color_n_max = max(slider_left) y_start_cur = slider_left[w_color_n_max] print(f'索引{initial_slider_left_x_index}左白值总和:{w_color_n_max}') for add_to_next in range(_pixel): back_color_n += img.getpixel((initial_slider_left_x_index + 1, y_start_cur + add_to_next)) print(f'索引{initial_slider_left_x_index}右白值总和:{back_color_n}') _color_diff_list[w_color_n_max - back_color_n] = initial_slider_left_x_index best_point = _color_diff_list[max(_color_diff_list)] print(f'最佳起点:{best_point}') return best_point 大家可以看到代码中的注释：# 滑块左边位置7px[6\13]处，获取滑块位置，为什么不是刚刚说的第七个像素，而是第七个像素到第十四个像素这样一个范围？因为拼块它有凹凸的部分，而且凹凸的程度还有不同的情况，我相信这也是极验增加机器模拟的难度的一种手段，规矩的图形太容易被定位了。所以这里需要准确的找到拼块的左描边的位置，还需要结合描边右侧的黑点数量进行判断定位。 我们得到了真正的拼块左边描x轴位置，其实也已经得到了拼块和缺口左边描y轴的上的范围。接下来我们只要使用这个y轴范围在x轴上寻找跟拼块左描边白点数基本相等的x值就能够得出缺口起始位置x值，可能会有缺口结束位置x值，也许还有背景描边满足该条件的x值。 def get_x_point_in_contour(bin_img_path=''): img = image.open(bin_img_path) # 拼块外部阴影范围 _shadow_width = 5 _pixel = 42 # 滑块左边位置7px[6\13]处（考虑凸在左的情况），获取滑块位置 slider_left_x_index = get_start_point(bin_img_path) slider_left = {} for y_cur in range(118): color_n = 0 for add_to_next in range(_pixel): color_n += img.getpixel((slider_left_x_index, y_cur + add_to_next)) slider_left[color_n] = y_cur y_max_col = max(slider_left) print(f'滑块左边白值总和:{y_max_col}') y_start_cur = slider_left[y_max_col] print(f'缺口图像y轴初始位置:{y_start_cur}') # 缺口出现范围大概在x轴[48-52+拼块阴影]-220 gap_left = {} for x_cur in range(slider_left_x_index + _pixel + _shadow_width, 220): color_n = 0 for y_cur in range(y_start_cur, y_start_cur + _pixel): color_n += img.getpixel((x_cur, y_cur)) gap_left[x_cur] = color_n _maybe = [] for x_cur in gap_left: if gap_left[x_cur] in range(int(y_max_col * 0.85), int(y_max_col * 1.3)): _maybe.append(x_cur) print(f'找到缺口可能位置{_maybe}') # 没找到暂时返回滑块长度加滑块起始位置 if len(_maybe) == 0: return 42 + slider_left_x_index, slider_left_x_index elif len(_maybe) == 1: return _maybe[0], slider_left_x_index # 多个结果，则找相邻（缺口内不会有太多干扰元素）结果间差距在38-43之间的第一个数 _max_diff = {} for i in range(len(_maybe) - 1): if _maybe[i + 1] - _maybe[i] in range(38, 43): return _maybe[i], slider_left_x_index else: _max_diff[_maybe[i + 1] - _maybe[i]] = _maybe[i] return _max_diff[max(_max_diff)], slider_left_x_index 这部分代码有点重复，拼块左描边白点数以及y轴范围已经在get_start_point函数中求得了，直接返回使用即可。缺口开始的位置可能是x轴索引48到52（根据拼块的真正起始点而定），一直到259-42=217的范围内（代码中我直接写了220），因为拼块的外部阴影造成了多重描边，所以我们还需要剔除掉右描边的阴影部分。大家能看到我定的规则是白点数满足(0.85至1.3)倍的拼块左描边白点数，即视为可能的位置。实际上它们白点数应该是相差极少，甚至可以说是相等的，大家可以通过实验去调优这里的倍数参数，也许还能剔除掉更多的干扰。最后考虑到得到的结果有可能除了真正的起点和终点外，还有其他的一些干扰，所以做了简单的判断，实际上就当前所知的背景图来看，不会出现这种情况。到这里我们已经得到了解决问题的所有钥匙了，接下来就是用钥匙打开新世界大门的时候了。 3、将拼图移动到缺口处 这一节相对比较简单，拖动操作使用selenium的ActionChains来实现，上面得到的缺口起始x值和拼块真实的起点值相减，就得到了移动的实际距离，然后直接拖动过去就可以了？确实可以，可以重头来过了。极验会根据整个移动过程的速度判断你是机器还是人，不是说快慢的问题，而是正常的人类行为在移动中速度是会变化的，最真实的情况就是你在接近缺口的时候会减速。根据物理学原理（早就忘了），我写了一个匀加速运动（实际上并不匀）来模拟人类拖动，因为move_by_offset会自动将偏移量转成整形类型，所以我还是自己先转好了。 def btn_slide(browser, x_offset=0, _x_start=6): # 开始位置右偏6-13像素 x_offset = abs(x_offset - _x_start + 1) slider = browser.find_element_by_class_name(&quot;geetest_slider_button&quot;) ActionChains(browser).click_and_hold(slider).perform() section = x_offset left_time = 1 x_move_list = get_x_move_speed(x_offset, left_time, section) print(f'魔鬼的步伐：{x_move_list}') print(f'实际应该移动距离:{sum(x_move_list)}') for x_move in x_move_list: ActionChains(browser).move_by_offset(x_move, yoffset=0).perform() ActionChains(browser).release().perform() time.sleep(2) browser.close() def get_x_move_speed(distance=0, left_time=0, section=10): origin_speed = distance * 2 acc_speed = origin_speed / left_time / left_time / section move_offset = [] new_speed = origin_speed for i in range(0, section): new_speed = new_speed - acc_speed move_offset.append(round(new_speed / section)) if sum(move_offset) &gt;= distance or (round(new_speed / section)) == 0: break if sum(move_offset) &lt; distance: move_offset.append(distance - sum(move_offset)) return move_offset 最后的实际效果 Your user agent does not support the HTML5 Video element. 好了，我的整个实验就到这里就结束了，下面还有一些其他方面的思考。如果有能看到这里的童鞋，既然来了，不如在评论留下一个脚印？ 4、后续：关于干扰块排除的想法 相信大家都能发现，背景图里面，很多时候会在随机的位置出现另外一个或多个&quot;缺口&quot;，它们的颜色相对真正的缺口来说浅一些，但是对于上面方案二的描边法来说，它们确实也是会被描绘出来，虽然我们利用拼块确定了y轴的范围，但是当这些假的&quot;缺口&quot;也在这个y轴范围内的时候，特别是凹凸和方向完全跟真实缺口一样的时候，我们上面的代码就没办法分辨到底哪个才是真正的缺口了。但是解决这个问题的办法也比较简单，我这里想到的思路有两种： 得到的两个位置获取它们原图颜色，相对较深的为真 所有得到的缺口位置都记录下来，先移动到第一个缺口位置，若是不成功，再移动到下一个缺口位置 不管怎样的干扰，总不会喧宾夺主。因为毕竟是给人类辨认的，而机器，只要你制定适当的规则，它们的辨识能力能够达到远超人类的水准。 5、后续：关于增加定位模拟难度的想法 相信大家看完了实验的整个过程，在这里一定会有很多关于如何设计更加复杂、更有效防止机器模拟行为的验证码的想法，我这里也就这次实验中的滑动验证码发表一下自己的看法。 可以说滑动验证码是国内一种比较新颖的人机校验方式，因为他的操作简单直观，适用于任何年龄层的互联网用户。那实际人机校验的效果如何呢？如果仔细读完上文或者对滑动验证码有研究的童鞋，应该都知道，它实际上是进行了两次校验：识别和行为，我个人认为它能够更好的保护我们的应用以及用户数据，所以现在在国内它的普及度也是相当高。而我这次的实验针对当前版本进行制定规则以实现了机器模拟的目的，但我认为滑动验证码可以通过以下的调整来比较有效增加模拟的难度： 拼块滑动不限于x轴，可在图内任意移动 拼块和缺口的形状改为非固定的多边形或不规矩形状 最最最最后，我想说的是，验证码技术经过多年的发展现在已经相当成熟了，除了日常的数字字母验证码，这次实验的滑动验证码，相信大家也听说过无比牛b的12306验证码，还有google的recaptcha等等。虽然当今的验证码领域已经有如此多的优秀方案，但是我相信没有一个方案能够百分百的抵御机器人，你有世界上最优秀的工程师、科学家，他有这个世界上最有钱的老板啊，把你的工程师和科学家撬过来破解还不是两天的事。现代互联网技术就是在这样的攻防游戏中逐渐的发展壮大的，时代的巨轮滚滚向前，跟不上时代步伐的技术只会被碾压得粉碎。 完。]]></content>
      <categories>
        <category>有趣</category>
      </categories>
      <tags>
        <tag>other</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo踩坑记]]></title>
    <url>%2F2018%2F08%2F10%2Fhexo%E8%B8%A9%E5%9D%91%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[hexo的搭建和使用十分的方便，搭配github page食用更佳。github上有很多绚丽的hexo主题，大家可以按需搭配。虽说hexo+github page搭建个人博客很方便快捷，但如果你需要较多的个性化定制，坑总是会踩的。本文主要遇到的各种坑以及记录简单的操作步骤，如果需要详细的安装部署教程请点击传送门离开。 安装hexo 如果你不知道或者未安装 npm ，点击此处了解以及下载。 npm i -g hexo-cli 说到npm我在后面挖到了一个坑，这个坑以前已经挖过，这里又遇到了，有必要记下来。如果你跟我一样是在使用Windows 10 + VirtualBox (VBox) + Vagrant + Laravel Homestead + 共享目录这样的环境做开发的，需要注意。 在上述环境中使用npm会有比较多意料之外的状况，大部分stackoverflow上都有解决方案，但这次遇到的error “ETXTBSY: text file is busy” on npm install弄了一段时间仍然没解决，把npm搞坏后还是换到windows环境去了。 虽然没解决，但还是推荐一下比较靠谱的解决方案。 快速搭建 hexo init [folder] //初始化，新建一个网站。如果没有设置 folder ，Hexo 默认在目前的文件夹建立网站 cd folder //进入网站根目录，如果没有设置 folder ，则不需要该步骤 hexo g //generetor的缩写，生成静态文件。 hexo s //server的缩写，启动服务器。默认情况下，访问网址为： http://localhost:4000/。 主题 hexo有很多主题可以提供选择，而我这里则使用了material这个主题，最坑的是他的文档网站ssl证书居然过期了，想看都看不了=。=那就没办法啦，咱一起逐个配置试一下，再问一问Google，应该也不会有啥大问题。 首先我们把material的项目clone下来放到hexo目录下的themes中，根据说明为了避免配置文件被覆盖，我们需要复制一份_config.template.yml并命名为_config.yml。接下来我们的就开始定制我们自己的主题风格。_config.yml中大多数的配置项都有简单的说明，配置完各种基本信息后，我们想要配置一些个性化的东西，例如代码的高亮样式、选择自己喜欢熟悉的评论系统等等。 高亮 首先说说配置代码高亮样式，在备注Code highlight下有两个配置项 # Code highlight # You can only enable one of them to avoid issues. # Also you need to disable highlight option in hexo's _config.yml. # # Prettify # theme: # Available value in /source/css/prettify/[theme].min.css prettify: enable: false theme: &quot;github-v2&quot; # Hanabi (https://github.com/egoist/hanabi) # line_number: [true/false] # Show line number for code block # includeDefaultColors: [true/false] # Use default hanabi colors # customColors: This value accept a string or am array to setting for hanabi colors. # - If `includeDefaultColors` is true, this will append colors to the color pool # - If `includeDefaultColors` is false, this will instead default color pool hanabi: enable: true line_number: true includeDefaultColors: true customColors: 上面是各种高亮的样式选择，而下面则是hanabi，一个很骚的高亮风格（没错就是我用着的这个）。这里需要注意的是这两个配置项你只能设置其中一个enable为true，而且hexo的_config.yml中有一个配置项跟它是冲突的 # Writing new_post_name: :title.md # File name of new posts default_layout: post titlecase: false # Transform title into titlecase external_link: true # Open external links in new tab filename_case: 0 render_drafts: false post_asset_folder: false relative_link: false future: true highlight: enable: false line_number: false auto_detect: false tab_replace: 这里的highlight设置为true会让hanabi不起作用。如果你选用prettify的话，可以在路径material/source/css/prettify/[theme].min.css找喜欢的高亮样式，其中[theme]就是prettify.theme中填写的样式名称。 评论系统 大家可以看到，集成服务里面，包含了评论系统的配置项，如此方便的配置就能够加入一个评论系统到博客里了，何乐而不为呢？ # Comment Systems # Available value of &quot;use&quot;: # disqus | disqus_click | changyan | livere | gitment | gitalk | valine | wildfire # If you want to use gitment or gitalk,you should get the client_id and client_secret from https://github.com/settings/applications/new # If you want to use valine,you should get the app_id and app_key from https://leancloud.cn ,more setting please see https://valine.js.org comment: use: gitalk shortname: # duoshuo or disqus shortname changyan_appid: changyan_conf: changyan_thread_key_type: path livere_data_uid: gitment_repo: # git repo of the hexo gitment_owner: # git repo's owner gitment_client_id: # github app client id gitment_client_secret : # github app client secret valine_leancloud_appId: # leancloud application app id valine_leancloud_appKey: # leancloud application app key valine_notify: false # valine mail notify (true/false) https://github.com/xCss/Valine/wiki valine_verify: false # valine verify code (true/false) valine_pageSize: 10 # comment list page size valine_avatar: identicon # gravatar style https://valine.js.org/#/avatar valine_lang: zh-CN # i18n valine_placeholder: Just go go # valine comment input placeholder(like: Please leave your footprints ) valine_guest_info: nick,mail,link #valine comment header info gitalk_repo: gitTalk gitalk_owner: tomhaoye gitalk_client_id: ksjhdfkhfksdhfjsdhf gitalk_client_secret: jd12809j890sjhdosihdoaishd9o21d9081h2yd0 wildfire_database_provider: firebase # firebase or wilddog wildfire_wilddog_site_id: wildfire_firebase_api_key: wildfire_firebase_auth_domain: wildfire_firebase_database_url: wildfire_firebase_project_id: wildfire_firebase_storage_bucket: wildfire_firebase_messaging_sender_id: wildfire_theme: light # light or dark wildfire_locale: zh-CN # en or zh-CN 大家可以看到，集成的评论系统有：disqus，disqus_click，changyan，livere，gitment，gitalk，valine，wildfire，大家喜欢哪个就就配置对应的配置项就可以了。例如我使用的gitalk，只需要在个人设置中选择开发者设置，然后选择Oauth Apps，新建一个授权应用，将得到的Client ID和Client Secret填到上面的gitalk_前缀配置项中，gitalk_repo填写你的应用名称，gitalk_owner填写你的账号名即可。 当然配置不是重点，这篇文章主要是记录踩过的坑，没趴下过的地方我也不会特别提出来。我完完整整的配置好了我的的gitalk评论系统后，先新建了一片文章并打开链接，评论系统自动请求并在github的仓库里面新增了一个issue，据我猜测这个issue就是用来记录当前文章的所有评论的。果不其然，我在发表了一条评论，issue里面便新增了留言一段记录。嗯，一切都十分的顺利，于是我又新建了一篇名字比较长的文章并打开链接，咦？怎么请求发生了错误？后来在Google查了半天，终于发现gitalk的初始化id参数最长只能传50个字符，而它默认是直接拿当前的url作为参数的，所以请求会返回客户端错误。知道了问题所在解决就比较简单了，只需要在theme/material/layout/_widget/comment/gitalk/main.ejs中加入： &lt;script&gt; var gitalk = new Gitalk({ clientID: '&lt;%= theme.comment.gitalk_client_id %&gt;', clientSecret: '&lt;%= theme.comment.gitalk_client_secret %&gt;', repo: '&lt;%= theme.comment.gitalk_repo %&gt;', owner: '&lt;%= theme.comment.gitalk_owner %&gt;', admin: ['&lt;%= theme.comment.gitalk_owner %&gt;'], id: document.title.substr(0,50), // facebook-like distraction free mode distractionFreeMode: false }) gitalk.render('gitalk-container') &lt;/script&gt; 这里我是将title截取最多50个字符，大家也可以结合自身情况传入自己需要的参数。 Emoji表情渲染 Hexo默认的markdown渲染引擎不支持emoji表情的渲染，为了美化博客，我们可以更换一个支持emoji的渲染引擎，并添加一个emoji插件。方法很简单，只需要键入以下三行命令： npm un hexo-renderer-marked --save npm i hexo-renderer-markdown-it --save npm install markdown-it-emoji --save 全部安装成功后在Hexo的_config.yml配置文件中加入以下的配置： ## markdown 渲染引擎配置，默认是hexo-renderer-marked，这个插件渲染速度更快，且有新特性 markdown: render: html: true xhtmlOut: false breaks: true linkify: true typographer: true quotes: '“”‘’' plugins: - markdown-it-footnote - markdown-it-sup - markdown-it-sub - markdown-it-abbr - markdown-it-emoji anchors: level: 2 collisionSuffix: 'v' permalink: true permalinkClass: header-anchor permalinkSymbol: '' 在emojy-cheet-sheet中找到你想要的表情编码，例如笑脸对应的emoji编码是:smile:，清除旧文件并重新构建后在你的文章中就可以会出现😄了。 没有结束 由于博客还在搭建美化中，该文章会持续更新。。。]]></content>
      <categories>
        <category>挖坑</category>
      </categories>
      <tags>
        <tag>other</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP Standard Recommendation]]></title>
    <url>%2F2018%2F06%2F16%2FPHP-Standard-Recommendation%2F</url>
    <content type="text"><![CDATA[非官方规范。 PSR-0(AutoLoading Standard) (14年10月21日起标记为deprecated，由PSR-4代替) 完全合格的命名空间和类名必须有以下结构 &quot;\&lt;vendor name&gt;\(&lt;Namespace&gt;)*&lt;Class Name&gt;&quot; 每个命名空间必须有顶级命名空间 (&quot;Vendor Name&quot;) 每个命名空间可以有任意多个子命名空间 每个命名空间在被从文件系统加载时必须被转换为操作系统的路径分隔符 每个&quot;_“字符在类名中被转换为DIRECTORY_SEPARATOR。”_&quot;在命名空间中没有明确含义 符合命名标志的命名空间和类名必须以&quot;.php&quot;结尾来加载 VendorName、命名空间、类名可以由大小写字母组成，其中命名空间和类名是大小写敏感的以保证多系统兼容 PSR-1(Basic Coding Standard) 源文件必须只使用以下这两种标签 &lt;?php 和 &lt;?= 源文件中php代码的编码格式必须只适用不带BOM的UTF－8（BOM——字节顺序标记） 一个源文件建议只用来做声明（类、函数、常量等）或者只用来做一些引起副作用的操作（如输出信息，修改配置文件等），但不应该同时做这两件事 命名空间和类必须遵守PSR-0 类名必须使用StudlyCaps写法 类中的常量必须只由大写字母和下划线组成 方法名必须使用camelCase写法 PSR-2(Coding Style Guide) 代码必须遵循PSR-1 代码必须使用4个空格进行缩进，而不是制表符 一行代码的长度不应该有硬限制，软限制为120个字符，建议每行小于80 在命名空间声明下必须空一行，use下同理 类的左、右花括号必须各自成一行 方法的左右花括号都必须各自成一行 所有属性、方法必须有可见性声明；abstract和final必须在可见性声明前，static必须在可见性声明后 在结构控制的关键字后必须空一格；函数调用后面不可有空格 结构控制关键字左花括号必须同一行，右花括号必须放在代码主体下一行 控制结构的左花括号之后不可有空格，右花括号之前也不可有空格 PSR-3(Logger Interface) LoggerInterface暴露八个接口用来记录八个等级(debug,info,notice,warning,error,critical,alert,emergency)的日志 第九个方法是log，接受日志等级操作为第一个参数。用一个日志等级常量来调用这个方法必须和直接调用指定等级方法的结果一致。用一格本规范中来定义且不为具体实现所知的日志等级来调用该方法必须跑出一个 PSR\Log\InvalidArgumentException 不推荐使用自定义的日志等级，除非你非常确认当前类库对其支持。 PSR-4(Improved AutoLoading) (兼容PSR-0) 术语［类］是一个泛称，它包含类、接口、trait及其他类似结构 完全限定类名应该如下范例 &lt;NamespaceName&gt;(&lt;SubNamespace&gt;)*&lt;ClassName&gt; 完全合规类名必须有一格顶级命名空间 完全合规类名可有多个子命名空间 完全合规类名应该有一格终止类名 下划线在完全合规类名中是没有特殊含义的 字母在完全合规类名中可以是任何大小写组合 所有类名必须以大小写敏感的方式引用 当完全合规类名载入文件时： 在完全合规类名中，连续的一个或几个子命名空间构成的命名空间前缀（不包括顶级命名空间分隔符），至少对应一格基础目录 在［命名空间前缀］后的连续子命名空间名称对应一个［基础目录］下的子目录，其中的命名空间分隔符标示目录分隔符。子目录名称必须和子命名空间名大小写匹配 终止类名对应一个以.php结尾的文件。文件名必须和终止类名大小写匹配 自动载入器的实现不可以抛出任何异常，不可以引发任何等级的错误，也不应该有返回值]]></content>
      <categories>
        <category>规范</category>
      </categories>
      <tags>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IO模型笔记]]></title>
    <url>%2F2018%2F05%2F20%2FIO%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[IO Model 常见IO模型 blocking IO nonblocking IO IO mutiplexing(select &amp; poll) signal driven IO asynchronous IO(the POSIX aio_functions) 一个基本的IO，它会涉及到两个系统对象，一个就是系统内核，另一个是调用这个IO的对象。当一个read操作发生时，会经历以下阶段： 通过read系统调用向内核发起读请求 内核向硬件发送读指令，并等待读就绪 内核把将要读取的数据复制到描述符所指向的内核缓存区 将数据从内核缓存区拷贝到用户进程空间中 同步与异步 同步和异步关注的是消息通信机制 注：同步IO过程由进程处理，异步IO交由内核处理IO 阻塞与非阻塞 阻塞和非阻塞关注的是程序在等待调用结果时的状态 1，2，3，4属于同步IO，5属于异步IO AIO异步非阻塞IO，适用于连接数多且IO时间长的架构，如相册服务器，JDK7开始支持 NIO同步非阻塞IO，适用于连接数多且轻操作（IO?）的架构 BIO同步则色IO，适用于连接数少且固定的架构 一般来说，IO主要有两种情况（服务器）：一是来自网络的IO，二是文件的IO。windows提供异步IO，Linux提供epoll模型给网络IO，文件IO则提供AIO epoll,select/poll 本质上都是同步IO，自己处理IO过程，但是epoll优化了轮询操作，使用callback机制响应。 额外提供Edge Triggered，用户空间可能缓存IO状态，减少epoll-wait／epoll-pwait调用 level triggered &amp; edge triggered LT事件不会丢弃，只要读buffer里面有数据可以让用户读，就会不停的通知。而ET则只发在事件发生之时通知。 select缺点： 每次调用，都需要把fd集合从用户态拷贝到内核态，fd多事件开销大 每次都要遍历进入内核的fd，开销也很大 select支持fd数量太小，默认1024 poll与select只在fd集合的结构上面有区别 epoll对select缺点的改进 新事件注册到epoll句柄中，会把所有的fd拷贝进内核，而不是在epoll_wait时重复拷贝 为fd指定回调函数，设备就绪，调用回调函数唤醒等待者，并将fd加入就绪链表 最大的限制很大程度上跟系统内存大小有关 消息传递：mmap加速 总结 select、poll都需要轮询遍历所有fd，而epoll只需要读取就绪链表 select、poll每次调用都copy一次fd，并往设备队列上挂。而epoll只要copy一次fd，并只往自己的等待队列上挂一次即可]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux添加服务到开机自动启动]]></title>
    <url>%2F2018%2F04%2F22%2FLinux%E6%B7%BB%E5%8A%A0%E6%9C%8D%E5%8A%A1%E5%88%B0%E5%BC%80%E6%9C%BA%E8%87%AA%E5%8A%A8%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[Systemd 是 Linux 系统中最新的初始化系统，Systemd 服务文件以 .service 结尾。一些使用包管理工具安装的软件会自动建立 .service 服务文件，路径在 /lib/systemd/system/ 下，但自行建立及管理的文件建议放在 /etc/systemd/system/ 目录下。内容以 supervisor 为例： [Unit] Description=Supervisor process control system for UNIX Documentation=http://supervisord.org After=network.target [Service] ExecStart=/usr/bin/supervisord -n -c /etc/supervisor/supervisord.conf ExecStop=/usr/bin/supervisorctl $OPTIONS shutdown ExecReload=/usr/bin/supervisorctl -c /etc/supervisor/supervisord.conf $OPTIONS reload KillMode=process Restart=on-failure RestartSec=50s [Install] WantedBy=multi-user.target 参数说明： [Unit] Description：描述服务 Documentation：参考资料 After：描述服务类别 [Service] Type：是后台运行的形式 ExecStart：服务的具体运行命令 ExecReload：重启命令 ExecStop：停止命令 KillMode：daemon终止时所关闭的程序 Restart：触发重启 RestartSec：重启等待时间 TimeoutSec：无法顺利启动强制关闭时间 注意：[Service]的启动、重启、停止命令全部要求使用绝对路径 [Install] 运行级别下服务安装的相关设置，可设置为多用户，即系统运行级别为3 如过想要某些服务开机启动，例如以 php-fpm 为例，编写service： sudo vi /etc/systemd/system/php7.1-fpm.service [Unit] Description=The PHP 7.1 FastCGI Process Manager Documentation=man:php-fpm7.1(8) After=network.target [Service] Type=notify PIDFile=/run/php/php7.1-fpm.pid ExecStart=/usr/sbin/php-fpm7.1 -R --nodaemonize --fpm-config /etc/php/7.1/fpm/php-fpm.conf ExecReload=/bin/kill -USR2 $MAINPID [Install] WantedBy=multi-user.target 随后如果 php-fpm 在运行则先将其关闭，运行： systemctl daemon-reload systemctl start php7.1-fpm.service 测试能够成功开启服务了，就可以将服务设置为开机启动： systemctl enable php7.1-fpm.service 常用命令 systemctl daemon-reload systemctl list-units --type=service systemctl list-unit-files --type=service systemctl start unit.service systemctl stop unit.service systemctl restart unit.service systemctl enable unit.service systemctl disable unit.service systemctl is-enable unit.service systemctl is-active unit.service systemctl status unit.service]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F03%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[欢迎来到我的博客 public class HelloWorld { public static void main(String[] args) { System.out.println(&quot;Hello,World!&quot;); } } #include &lt;stdio.h&gt; int main() { printf(&quot;Hello,World!&quot;); return 1; } var sys = require(&quot;sys&quot;); sys.puts(&quot;Hello,World!&quot;); &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;body&gt; &lt;h1&gt;This is the first program!&lt;/h1&gt; &lt;p&gt;Hello,World!&lt;/p&gt; &lt;/body&gt; &lt;/html&gt;]]></content>
      <categories>
        <category>闲聊</category>
      </categories>
      <tags>
        <tag>other</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2017年9-11月游记——贵州]]></title>
    <url>%2F2017%2F09%2F15%2F2017%E5%B9%B49-11%E6%9C%88%E6%B8%B8%E8%AE%B0%E2%80%94%E2%80%94%E8%B4%B5%E5%B7%9E%2F</url>
    <content type="text"><![CDATA[读万卷书，走万里路 前言 大学时期一开始过得有点迷茫，上上课、去去社团，等到能码两行代码的时候，就开始跟老师同学搞搞小项目，眨眼间两年过去了，感觉生活有点平淡。萌生了想出去走走的想法，然而当计划到一半的时候，机缘巧合接触到了一个感兴趣的创业项目，于是跟随着一位师兄创业去了，一直到毕业一年后才想起当初对旅行的憧憬，于是决定重新计划一下路线和行程。 前前后后一共花了一个多个月的闲余时间去准备，确定了自己的大概路线，然后查找每个地方的攻略，接着查地图、交通等等。终于在在九月中旬，我一大早到达了广州南站，搭上了开往贵阳的列车。 第一站，贵阳 我这次的路线规划决定以中国西北部省市为主，加以拷问了自己的内心，得出了几个最想去的地方，而贵阳是离我最近的一个。在车上看看风景听听歌睡睡觉，4个小时的时间很快就过去了，而我也顺利到达了贵阳高铁站。之前预定的青旅离高铁站很近，走了大概15分钟就到了。 提前打电话给了青旅老板，很快在小区里面就碰面了。老板领着我去登记了信息后就带我到我的房间去了，聊着聊着才发现这个地方属于郊外，这整个小区基本都是被各种老板买下来做短租旅馆之类的，旺季的时候基本每个房间都塞满人，但现在属于淡季，所以晚上附近很少人，尽量少在晚上外出，平时外出也尽量在天黑前回来。因为到达的时间是中午，我本来是打算先在下面的餐馆吃一顿就回青旅睡一觉，晚上再出去走走的，不过既然老板这样说了，那我就决定吃完后就往城里出发吧。 虽然是郊区，但是交通还是很便捷，几乎所有公交车都可以到达市中心，车票也比较便宜，1块钱就行了。之前大概看了到达市中心的路程，大概需要一个小时，虽然路程是比较远，但是因为内心充满了好奇，所以一路上都觉得很精神。贵阳很多小山，所以地势起起伏伏，很多时候建筑都是依山而建的。不过这里大多数山都很矮，不像重庆那样，动不动几十层高。差不多四点钟的时候到了市中心的商业区，尽管现在是淡季，但是商业区很繁华，在附件商场逛了一下，一路上买点小吃吃，不过我在贵阳对吃的记忆并没多少，可能这里的风味都较为普通，也可能是我没有吃到真正的特色菜吧。 逛着吃着很快就到了晚上了，走到外面街上，周围的灯光色彩斑斓。咦，好像忘了点什么？噢，对了！要早点回去！不过既然都夜晚了，而且夜景这么好看，再看一阵子吧。😂 夜景虽好，但不能贪杯。否则，回过神来，就会发现已经九点多了。赶紧赶上车回程，快十一点才终于回到了青旅。之前老板跟我说今天这里只有你和另外一个人（长住），而且我们是两个房间的，我看时间也比较晚了，所以也没去打扰他，洗漱完之后遍躺上床睡觉了。 第二站，凯里 😄新的一天新的开始，第二天的行程是去西江千户苗寨，高铁票也是之前就订好了，同样是一大早到了高铁站（其实一点都不早😂）。 车跑得很慢，慢得不像高铁，但是路程很短，半小时的时间就到了。 一出高铁站，迎面而来的是各种拉客拼车的师傅，我之前看过攻略说过这种应该都是非法营运的，其实附近就有正规的旅游专线，于是我跟随大多数旅客的步伐，去附近的服务站报了个名，等待十人成团后便发车了。 大概一个多小时的车程，我们大概在十二点的时候到达了目的地。虽然不是很饿，但是景区大门有很多的小食摊，于是我决定先吃为敬。 吃饱喝足后，准备进寨子里去了。想进寨，先买票，买票的方式很多种，包括但不限于微信、支付宝、美团。票的种类也很多，包括但不限于单人门票、团体门票、单人套票、团体套票。令我感到意外的一点是，广东的身份证还能享受优惠！ 买完票排个队很快就进了寨子入口，然后会有个巴士会统一载到寨子里面去。 到达寨子后就大家就解散了，而我就先前往预定好的青旅里面先做好登记。 虽然看上去景点人超级多，但是选择青旅的游客貌似很少，前台帅哥告诉我今天只有三个人入住，而我的房间里面只有他和我。😂青旅里面有几只猫，但是可能平时被撸烦了，摸一下就跑掉了，很高冷。 猫好像是撸不了了，那就出去逛逛吧。把贵重的物品和日常用品放进小书包后，就往外走了，前台帅哥很贴心的跟我说如果晚上找不到路回来的话，就微信一下他，他会发个定位过来。我让他不用担心，因为我本来就是地图定位过来的哈哈，寒暄完我就大刀阔斧往外走了。 跟大多数古城一样，商业化的气息其实还是满足的，不过这样我觉得挺好，至少寨子里面就能够满足游客和居民的日常需求，不会要什么没什么。寨子其实挺大，再加上淡季的原因，所以在街上看到的人流密度比较低。不过在热门的观赏点，还是挤满了男女老少。 上图就是一个比较热门的观赏点，从寨子里面走上去大概要二十来分钟，寨子也提供观赏车服务，前两次（来回）免费（包含在票价里），后面好像是每次15块钱。逛着逛着很快就已经到晚上了，门票还包含了今晚的晚饭哈哈，晚饭吃了什么我是不记得了，不过戏倒是挺足的，重要的是我们也能参与其中。 吃饱看足后我变再次乘车前往全景观赏点了，因为晚上的灯饰会比较好看，所以排队的人数也很多，于是我决定跟着大多数人的步伐一起走上去。到了观赏点后发现人不是一般的多，十分艰难的挤到了围栏边，随手拍了一张： 😂其实是加了滤镜，不过观赏点人太多挤来挤去的拍照是真不容易。下面给大家看一下原滋原味的吧： 喂饱了手机就回青旅了，归程排队等车的人依然很多，所以我还是走回去了，也好慢慢的欣赏一下各个角度的苗寨。晚上十二点多外面依然很热闹，灯火也还很旺，一直到了一点多的时候才安静下来。 第二天起床，打包了还没干透的衣服，收拾好所有的行李，准备回贵阳然后转乘去重庆的火车。今天阳光正好，一扫昨天的阴霾，出门的时候大橘和小黑正在慵懒的晒太阳。 我选择了拼车去火车站，车上刚好有一对中年夫妻也是去贵阳的，于是路上我们就聊了起来。大哥大姐是北方人，在了广东开了工厂，最近由于一些原因工厂要闭厂一段时间，于是就出来玩了。他们问及我为何贵州就走这么点地方，我是跟他们说：我想去的就必须去，没规划到的，就看心情吧哈哈。然后我再问他们后面准备去哪，他们就回答我说：主要看心情吧，没有必须去的地方，只要两个人在一起就好了。这不是摆明虐我吗😂]]></content>
      <categories>
        <category>闲聊</category>
      </categories>
      <tags>
        <tag>other</tag>
      </tags>
  </entry>
</search>
